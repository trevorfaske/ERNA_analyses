{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNP filtering using vcftools   \n",
    "\n",
    "## Filter ERNA_phylo using the same metrics as filtering without outgroup\n",
    "### Do not remove individuals\n",
    "\n",
    "use preferred conda env  \n",
    "**Packages needed**: vcftools, bgzip, tabix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things we filter on:  \n",
    "\n",
    "#### Individuals:  \n",
    "- **Coverage**: Also can be thought of as **depth**.See 3mapping. Calculated on bam files. Average read count per locus per individual. \n",
    "- **Missing**: Proportion of missing data allowed across all loci for individual. Common and high in GBS/RADseq data. Kinda an issue all around. Many methods, including PCA (all ordination methods), require a complete matrix with no missing data. Additionally, PCA will cluster by missing data with individuals with higher missing data clustering closer to the center and get this \"fan\" effect. Can be the same for coverage too. This (among other reasons) is why people use a variance-covariance matrix of genetic data to do ordinations. Other methods involve imputation. This can be fancy and use phased haplotype data OR simply, when you z-score, (g - mean(g))/sd(g), your genotype data across each locus, you make all missing data equal to 0 or Mean (i.e., the global allele frequency). There's more to this standardization, see *Patterson et al. 2006* (https://dx.plos.org/10.1371/journal.pgen.0020190) for more info. See PCAsim_ex in examples directory for showing all these issues.\n",
    "    - (additional) This is another reason to use entropy. Entropy is a hierarchical bayesian model so it gets an updated genotype estimate for each missing value based on genotype likelihoods across loci, individuals, and the allele frequency of the cluster/deme that individual assigns to.   \n",
    "    \n",
    "#### Loci:  \n",
    "- **Biallelic**: Only keep biallelic SNPs. Multiallelic SNPs are rare at the time scale we work (Citation??) and also,  mathematical nightmare and we have enough data so just ignore. Everyone does unless deep time phylogenetics. \n",
    "- **thin**: Keeps one locus within a specified range. Not 100% how it decides with one to keep. I think it's on quality or depth. This is a necessary step as loci in close physical are prone to sequencing error and linkage disequalibrium (LD) confounds many different population genetic parameters. For *de novo* reference assemblies, we thin to 100 as contigs/reads are ~92 bp in length. This keeps one locus per contig to control for LD and sequencing error, which is really common in pop gen and necessary for many analyses.   \n",
    "- **max-missing** = max proportion of missing data per locus  \n",
    "- **MAF** = minor allele frequency. Proportion of individuals a alternate allele needs to be present in order for that locus to be kept as a SNP. (e.g. maf = 0.02 for 250 individuals means that an alternate allele needs to be present in at least 5 individuals to be kept) Many papers have shown this is a big issue in clustering and demography (Citation). We do this a second time near the end if we removed individuals during missing data filtering.   \n",
    "- **Mean Depth**: Average allelic depth or read depth per locus. Too low could be sequencing error, too high could be PCR replication artifact (Citation).    \n",
    "- **Qual**: Locus Quality. You can look up the math. Usually above 20-30 is good but given our coverage and number of individuals, we can usually go way higher.     \n",
    "- **Fis**: Inbreeding coefficient. This is a contentous topic. This has to do with paralogs or paralogous loci. This is where loci map to multiple regions of the genome. Issues in highly repeative genomes. Usually leads to an excess of heterozygotes. Filtering on negative Fis can help. See these two McKinney papers (https://onlinelibrary.wiley.com/doi/10.1111/1755-0998.12763, https://onlinelibrary.wiley.com/doi/abs/10.1111/1755-0998.12613). Katie and others in the lab use his package called HDPlot to deal with this.   \n",
    "\n",
    "\n",
    "**See methods_ex.Rmd in examples directory for text** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {}
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import ipyparallel as ipp\n",
    "import os\n",
    "from os import environ\n",
    "import gzip\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import glob\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcftools = \"vcftools\"\n",
    "bgzip = \"bgzip\"\n",
    "tabix = \"tabix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo\n"
     ]
    }
   ],
   "source": [
    "cd $root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cp vcf.gz from vcf_dir to filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp vcf/ERNA_phylo.vcf.gz filtering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = os.path.join(root,\"filtering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo/filtering\n"
     ]
    }
   ],
   "source": [
    "cd $analysis_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count snps in zipped vcf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo/filtering/ERNA_phylo.vcf.gz'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_file = os.path.join(analysis_dir, \"ERNA_phylo.vcf.gz\")\n",
    "assert os.path.exists(vcf_file)\n",
    "vcf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606502\r\n"
     ]
    }
   ],
   "source": [
    "!zcat $vcf_file | grep -v '#' | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keep only biallelic loci as first step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf /data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo/filtering/ERNA_phylo.vcf.gz\n",
      "\t--recode-INFO-all\n",
      "\t--max-alleles 2\n",
      "\t--min-alleles 2\n",
      "\t--out ERNA_phylo.biallelic\n",
      "\t--recode\n",
      "\t--remove-filtered-all\n",
      "\t--remove-indels\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting VCF file...\n",
      "After filtering, kept 1311827 out of a possible 1606502 Sites\n",
      "Run Time = 1504.00 seconds\n"
     ]
    }
   ],
   "source": [
    "!$vcftools --remove-indels \\\n",
    "--min-alleles 2 \\\n",
    "--max-alleles 2 \\\n",
    "--remove-filtered-all \\\n",
    "--recode \\\n",
    "--recode-INFO-all \\\n",
    "--gzvcf \\\n",
    "$vcf_file \\\n",
    "--out $'ERNA_phylo.biallelic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_biallelic = os.path.join(analysis_dir, \"ERNA_phylo.biallelic.recode.vcf\")\n",
    "vcf_biallelic_gz = vcf_biallelic + '.gz'\n",
    "!$bgzip -c $vcf_biallelic > {vcf_biallelic_gz}\n",
    "!$tabix {vcf_biallelic_gz}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove by MAF, missing data, and thin   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf /data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo/filtering/ERNA_phylo.biallelic.recode.vcf.gz\n",
      "\t--recode-INFO-all\n",
      "\t--maf 0.02\n",
      "\t--thin 100\n",
      "\t--max-missing 0.7\n",
      "\t--out ERNA_miss70_thin100_MAF2\n",
      "\t--recode\n",
      "\t--remove-filtered-all\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting VCF file...\n",
      "After filtering, kept 32109 out of a possible 1311827 Sites\n",
      "Run Time = 165.00 seconds\n"
     ]
    }
   ],
   "source": [
    "!$vcftools \\\n",
    "--max-missing 0.7 \\\n",
    "--maf 0.02 \\\n",
    "--thin 100 \\\n",
    "--remove-filtered-all \\\n",
    "--recode \\\n",
    "--recode-INFO-all \\\n",
    "--gzvcf \\\n",
    "$vcf_biallelic_gz \\\n",
    "--out $'ERNA_miss70_thin100_MAF2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_filtered = \"ERNA_miss70_thin100_MAF2.recode.vcf\"\n",
    "vcf_filtered_gz = \"%s.gz\" % vcf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$bgzip -c $vcf_filtered > {vcf_filtered_gz}\n",
    "!$tabix {vcf_filtered_gz}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter snps further \n",
    "this needs to be done after removing individuals   \n",
    "\n",
    "### This uses vcftools to get some stats to summarize and make decisions with later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vcf_stats(vcf_gz):\n",
    "    \n",
    "    stats = ['depth',\n",
    "            'site-depth',\n",
    "            'site-mean-depth',\n",
    "            'site-quality',\n",
    "            'missing-site',\n",
    "            'freq',\n",
    "            'counts',\n",
    "            'hardy',\n",
    "            'het']\n",
    "    \n",
    "    for stat in stats:\n",
    "        !$vcftools --gzvcf $vcf_gz \\\n",
    "        --out $vcf_gz \\\n",
    "        {\"--%s\" % stat} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--depth\n",
      "\t--out ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting Mean Depth by Individual\n",
      "After filtering, kept 32109 out of a possible 32109 Sites\n",
      "Run Time = 4.00 seconds\n",
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--out ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--site-depth\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting Depth for Each Site\n",
      "After filtering, kept 32109 out of a possible 32109 Sites\n",
      "Run Time = 5.00 seconds\n",
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--out ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--site-mean-depth\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting Depth for Each Site\n",
      "After filtering, kept 32109 out of a possible 32109 Sites\n",
      "Run Time = 5.00 seconds\n",
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--out ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--site-quality\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting Quality for Each Site\n",
      "After filtering, kept 32109 out of a possible 32109 Sites\n",
      "Run Time = 2.00 seconds\n",
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--out ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--missing-site\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting Site Missingness\n",
      "After filtering, kept 32109 out of a possible 32109 Sites\n",
      "Run Time = 4.00 seconds\n",
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--freq\n",
      "\t--out ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting Frequency Statistics...\n",
      "After filtering, kept 32109 out of a possible 32109 Sites\n",
      "Run Time = 4.00 seconds\n",
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--counts\n",
      "\t--out ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting Frequency Statistics...\n",
      "After filtering, kept 32109 out of a possible 32109 Sites\n",
      "Run Time = 4.00 seconds\n",
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--hardy\n",
      "\t--out ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting HWE statistics (but only for biallelic loci)\n",
      "After filtering, kept 32109 out of a possible 32109 Sites\n",
      "Run Time = 5.00 seconds\n",
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--het\n",
      "\t--out ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting Individual Heterozygosity\n",
      "After filtering, kept 32109 out of a possible 32109 Sites\n",
      "Run Time = 4.00 seconds\n"
     ]
    }
   ],
   "source": [
    "get_vcf_stats(vcf_filtered_gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that will calculate various metrics we use to filter   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', 100)\n",
    "\n",
    "def get_MAF(row):\n",
    "    try:\n",
    "        return np.min([row.A1_freq, row.A2_freq])\n",
    "    except:\n",
    "        print(row)\n",
    "        \n",
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def calculate_Fis(vals):\n",
    "    try:\n",
    "        data = [float(x) for x in vals.split(\"/\")]\n",
    "        assert len(data) == 3\n",
    "        num_individuals = np.sum(data)\n",
    "        total_alleles = 2*num_individuals\n",
    "        a1_count = 2*data[0]\n",
    "        a2_count = 2*data[2]\n",
    "        het_count = data[1]\n",
    "        a1_count += het_count\n",
    "        a2_count += het_count\n",
    "        a1_freq = a1_count/total_alleles\n",
    "        a2_freq = a2_count/total_alleles\n",
    "        assert a1_freq + a2_freq == 1.0\n",
    "        He = 2 * a1_freq * a2_freq * get_correction(num_individuals)\n",
    "        Ho = het_count/num_individuals\n",
    "        Fis = 1 - (Ho/He)\n",
    "        return Fis\n",
    "    except:\n",
    "        return -9\n",
    "\n",
    "def combine_vcf_stats(filedir, prefix):\n",
    "    \n",
    "    hardy_files = !ls {filedir}/{prefix}.hwe\n",
    "    hardy = pd.read_csv(hardy_files[0], sep=\"\\t\")\n",
    "\n",
    "    hardy.columns = ['CHROM', 'POS', 'OBS(HOM1/HET/HOM2)', 'E(HOM1/HET/HOM2)', 'ChiSq_HWE',\n",
    "       'P_HWE', 'P_HET_DEFICIT', 'P_HET_EXCESS']\n",
    "    hardy.index = hardy.apply(lambda x: \"%s-%d\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    loci_files = !ls {filedir}/{prefix}.l* | grep -v log\n",
    "    loci_df = pd.concat([pd.read_csv(x, sep=\"\\t\", skiprows=0) for x in loci_files], axis=1)\n",
    "    chrom_pos = loci_df.iloc[:,0:2]\n",
    "    \n",
    "    frq_files = !ls {filedir}/{prefix}.frq* | grep -v count\n",
    "    frq_data = []\n",
    "    h = open(frq_files[0])\n",
    "    header = h.readline().strip().split()\n",
    "    for line in h:\n",
    "        frq_data.append(line.strip().split('\\t'))\n",
    "\n",
    "    header = ['CHROM', 'POS', 'N_ALLELES', 'N_CHR', 'A1_FREQ', \"A2_FREQ\"]\n",
    "    frq_df = pd.DataFrame(frq_data)\n",
    "    print(frq_df.columns)\n",
    "    #frq_df = frq_df.drop([6,7],axis=1)\n",
    "    frq_df.columns = header\n",
    "    frq_df.index = frq_df.apply(lambda x: \"%s-%s\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    loci_df = loci_df.drop(['CHROM','CHR','POS'], axis=1)\n",
    "    loci_df = pd.concat([chrom_pos, loci_df], axis=1)\n",
    "    loci_df.index = loci_df.apply(lambda x: \"%s-%d\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    loci_df = pd.concat([loci_df, frq_df, hardy], axis=1)\n",
    "    loci_df[\"A1_allele\"] = loci_df.apply(lambda row: row.A1_FREQ.split(\":\")[0], axis=1)\n",
    "    loci_df[\"A2_allele\"] = loci_df.apply(lambda row: row.A2_FREQ.split(\":\")[0], axis=1)\n",
    "    \n",
    "    loci_df[\"A1_freq\"] = loci_df.apply(lambda row: float(row.A1_FREQ.split(\":\")[1]), axis=1)\n",
    "    loci_df[\"A2_freq\"] = loci_df.apply(lambda row: float(row.A2_FREQ.split(\":\")[1]), axis=1)\n",
    "    \n",
    "    loci_df['MAF'] = loci_df.apply(get_MAF, axis=1)\n",
    "    loci_df = loci_df.drop(['CHROM', 'POS'], axis=1)\n",
    "    \n",
    "    loci_df['Fis'] = loci_df['OBS(HOM1/HET/HOM2)'].apply(calculate_Fis)\n",
    "    \n",
    "    return loci_df, frq_df, hardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERNA_miss70_thin100_MAF2.recode.vcf.gz'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_filtered_gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=6, step=1)\n"
     ]
    }
   ],
   "source": [
    "loci_df, frq_df, hardy = combine_vcf_stats(analysis_dir,'ERNA_miss70_thin100_MAF2.recode.vcf.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the summary stats and make decisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    32109.000000\n",
       "mean        13.587649\n",
       "std         27.893857\n",
       "min          1.609510\n",
       "25%          3.780980\n",
       "50%          5.546690\n",
       "75%         10.429500\n",
       "max        248.158000\n",
       "Name: MEAN_DEPTH, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loci_df.MEAN_DEPTH.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    32109.000000\n",
       "mean       946.895382\n",
       "std        144.150643\n",
       "min          9.639320\n",
       "25%        999.000000\n",
       "50%        999.000000\n",
       "75%        999.000000\n",
       "max        999.000000\n",
       "Name: QUAL, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loci_df.QUAL.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this would not be zero if there was an error in the calculation\n",
    "len(loci_df[loci_df.Fis == -9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3182, 28915)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loci_df[loci_df.MEAN_DEPTH > 25]),len(loci_df[loci_df.MEAN_DEPTH >= 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loci_df[loci_df.QUAL >= 100]) - len(loci_df[loci_df.QUAL >= 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1088, 2955, 5395)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loci_df[loci_df.QUAL <  500]), len(loci_df[loci_df.QUAL < 750]), len(loci_df[loci_df.QUAL < 999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(loci_df[loci_df.Fis <= -0.5]), len(loci_df[loci_df.MAF < 0.02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_snps(df, imputed=False):\n",
    "    if imputed:\n",
    "        return df[(df.MAF >= 0.01) &  \n",
    "                  (df.Fis > -0.5)]\n",
    "    else:\n",
    "        return df[(df.MEAN_DEPTH >= 3) & \n",
    "                  (df.MEAN_DEPTH < 25) & \n",
    "                  (df.QUAL >= 750) & \n",
    "                  (df.MAF >= 0.02) &  \n",
    "                  (df.Fis > -0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23306, 25)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loci_stage1 = filter_snps(loci_df)\n",
    "loci_stage1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir, \"stage1_positions.txt\"), \"w\") as o:\n",
    "    for elem in loci_stage1.index:\n",
    "        o.write(\"%s\\n\" % \"\\t\".join(elem.split(\"-\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf ERNA_miss70_thin100_MAF2.recode.vcf.gz\n",
      "\t--recode-INFO-all\n",
      "\t--out /data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo/filtering/good_snps\n",
      "\t--positions /data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo/filtering/stage1_positions.txt\n",
      "\t--recode\n",
      "\t--remove-filtered-all\n",
      "\t--remove-indels\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting VCF file...\n",
      "After filtering, kept 23306 out of a possible 32109 Sites\n",
      "Run Time = 28.00 seconds\n"
     ]
    }
   ],
   "source": [
    "!$vcftools --gzvcf $vcf_filtered_gz \\\n",
    "--remove-indels  \\\n",
    "--remove-filtered-all \\\n",
    "--recode \\\n",
    "--recode-INFO-all \\\n",
    "--positions {os.path.join(analysis_dir, \"stage1_positions.txt\")} \\\n",
    "--out {os.path.join(analysis_dir, \"good_snps\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "snps = os.path.join(analysis_dir, \"good_snps.recode.vcf\")\n",
    "snps_gz = snps + \".gz\"\n",
    "!$bgzip -c {snps} > {snps_gz}\n",
    "!$tabix {snps_gz}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make 012, see directory PCA_012 for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf /data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo/filtering/good_snps.recode.vcf.gz\n",
      "\t--012\n",
      "\t--out /data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo/filtering/good_snps.recode.vcf.gz\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Writing 012 matrix files ... Done.\n",
      "After filtering, kept 23306 out of a possible 23306 Sites\n",
      "Run Time = 5.00 seconds\n"
     ]
    }
   ],
   "source": [
    "!$vcftools --gzvcf {snps_gz} \\\n",
    "--out {snps_gz} \\\n",
    "--012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get coverage per individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VCFtools - 0.1.16\n",
      "(C) Adam Auton and Anthony Marcketta 2009\n",
      "\n",
      "Parameters as interpreted:\n",
      "\t--gzvcf /data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo/filtering/good_snps.recode.vcf.gz\n",
      "\t--depth\n",
      "\t--out /data/gpfs/assoc/denovo/tfaske/rabbit/full/REDO/phylo/filtering/good_snps.recode.vcf.gz\n",
      "\n",
      "Using zlib version: 1.2.11\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes for each ALT allele, in the same order as listed\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description=\"Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases\">\n",
      "After filtering, kept 589 out of 589 Individuals\n",
      "Outputting Mean Depth by Individual\n",
      "After filtering, kept 23306 out of a possible 23306 Sites\n",
      "Run Time = 4.00 seconds\n"
     ]
    }
   ],
   "source": [
    "!$vcftools --gzvcf {snps_gz} \\\n",
    "--out {snps_gz} \\\n",
    "--depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDV</th>\n",
       "      <th>N_SITES</th>\n",
       "      <th>MEAN_DEPTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN_AH_10</td>\n",
       "      <td>23306</td>\n",
       "      <td>9.03132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN_AH_11</td>\n",
       "      <td>23306</td>\n",
       "      <td>8.48756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN_AH_12</td>\n",
       "      <td>23306</td>\n",
       "      <td>10.01960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN_AH_13</td>\n",
       "      <td>23306</td>\n",
       "      <td>9.16494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN_AH_14</td>\n",
       "      <td>23306</td>\n",
       "      <td>6.08835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       INDV  N_SITES  MEAN_DEPTH\n",
       "0  EN_AH_10    23306     9.03132\n",
       "1  EN_AH_11    23306     8.48756\n",
       "2  EN_AH_12    23306    10.01960\n",
       "3  EN_AH_13    23306     9.16494\n",
       "4  EN_AH_14    23306     6.08835"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_file = os.path.join(analysis_dir, \"good_snps.recode.vcf.gz.idepth\")\n",
    "depth_df = pd.read_csv(depth_file, sep=\"\\t\")\n",
    "depth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    589.000000\n",
       "mean       7.220378\n",
       "std        1.952002\n",
       "min        1.698360\n",
       "25%        6.022050\n",
       "50%        7.482670\n",
       "75%        8.680640\n",
       "max       11.922200\n",
       "Name: MEAN_DEPTH, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_df.MEAN_DEPTH.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unnecessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘snps*’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm snps*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *miss*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
